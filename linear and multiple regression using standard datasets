multiple regression:

# import files
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
# load dataset and sort as train and test data
data=load_iris()
x,y=data.data,data.target
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=2)
# fit data using object
linreg = LinearRegression()
linreg.fit(x_train, y_train)
# calculate score
linreg.score(x_test,y_test)
y_pred=linreg.predict(x_test)
#plot using matplotlib
import matplotlib.pyplot as plt
plt.plot(x_test,y_test)


linear regression:


import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score
df = datasets.load_iris()
df['feature_names']
x,y=datasets.load_iris(return_X_y=True)
x.shape
y.shape
x=x[:, np.newaxis, 2]
x.shape
from sklearn.model_selection import train_test_split  
x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 1/3, random_state=0)  
# Create linear regression object
regr = linear_model.LinearRegression()

# Train the model using the training sets
regr.fit(x_train, y_train)
y_pred= regr.predict(x_test) 
# The coefficients
print("Coefficients: \n", regr.coef_)
# The mean squared error

print("Mean squared error: %.2f" % mean_squared_error(y_test,y_pred))

# The coefficient of determination: 1 is perfect prediction
print("Coefficient of determination: %.2f" % r2_score(y_test,y_pred))
# Plot outputs
plt.scatter(x_test,y_test, color="black")
plt.plot(x_test,y_pred, color="blue", linewidth=3)
plt.xlabel("sepal length")
plt.ylabel("flower category")
plt.xticks(())
plt.yticks(())

plt.show()

